{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs3Vxo5dmP7j"
   },
   "source": [
    "## Feature based classification \n",
    "\n",
    "### jey@aims.ac.za"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74QOVpN4WwRq"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "T-5ywHOxNb7y",
    "outputId": "9c5031cc-4d8a-46c7-d912-493d35a26978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-f_P0_9Zhcwx"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('https://drive.google.com/uc?export=download&id=1XpIaZzSMfyTUH-KFxpXFDsL1PZO_mrC0', header=None,\n",
    "                      names = ['region-centroid-col', 'region-centroid-row', 'region-pixel-count', 'short-line-density-5', \n",
    "                               'short-line-density-2', 'vedge-mean', 'vegde-sd', 'hedge-mean', 'hedge-sd', \n",
    "                               'intensity-mean', 'rawred-mean', 'rawblue-mean', 'rawgreen-mean', 'exred-mean', \n",
    "                               'exblue-mean', 'exgreen-mean', 'value-mean', 'saturatoin-mean', 'hue-mean', 'target'],delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0enHe6T-O4xs"
   },
   "source": [
    "## 1. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "CqLvznMeOY0a",
    "outputId": "b4b9dd2d-f580-491b-ab9c-634136b8a9f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region-centroid-col</th>\n",
       "      <th>region-centroid-row</th>\n",
       "      <th>region-pixel-count</th>\n",
       "      <th>short-line-density-5</th>\n",
       "      <th>short-line-density-2</th>\n",
       "      <th>vedge-mean</th>\n",
       "      <th>vegde-sd</th>\n",
       "      <th>hedge-mean</th>\n",
       "      <th>hedge-sd</th>\n",
       "      <th>intensity-mean</th>\n",
       "      <th>rawred-mean</th>\n",
       "      <th>rawblue-mean</th>\n",
       "      <th>rawgreen-mean</th>\n",
       "      <th>exred-mean</th>\n",
       "      <th>exblue-mean</th>\n",
       "      <th>exgreen-mean</th>\n",
       "      <th>value-mean</th>\n",
       "      <th>saturatoin-mean</th>\n",
       "      <th>hue-mean</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.547722</td>\n",
       "      <td>1.111109</td>\n",
       "      <td>0.544331</td>\n",
       "      <td>59.629630</td>\n",
       "      <td>52.444443</td>\n",
       "      <td>75.222220</td>\n",
       "      <td>51.222220</td>\n",
       "      <td>-21.555555</td>\n",
       "      <td>46.77778</td>\n",
       "      <td>-25.222221</td>\n",
       "      <td>75.222220</td>\n",
       "      <td>0.318996</td>\n",
       "      <td>-2.040554</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.250924</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.365148</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>-2.333333</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.123254</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944448</td>\n",
       "      <td>0.772202</td>\n",
       "      <td>1.111112</td>\n",
       "      <td>1.025597</td>\n",
       "      <td>123.037040</td>\n",
       "      <td>111.888885</td>\n",
       "      <td>139.777790</td>\n",
       "      <td>117.444440</td>\n",
       "      <td>-33.444443</td>\n",
       "      <td>50.22222</td>\n",
       "      <td>-16.777779</td>\n",
       "      <td>139.777790</td>\n",
       "      <td>0.199347</td>\n",
       "      <td>-2.299918</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.722222</td>\n",
       "      <td>1.781593</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.749488</td>\n",
       "      <td>43.592594</td>\n",
       "      <td>39.555557</td>\n",
       "      <td>52.888890</td>\n",
       "      <td>38.333336</td>\n",
       "      <td>-12.111111</td>\n",
       "      <td>27.88889</td>\n",
       "      <td>-15.777778</td>\n",
       "      <td>52.888890</td>\n",
       "      <td>0.266914</td>\n",
       "      <td>-1.998858</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>1.515353</td>\n",
       "      <td>2.611111</td>\n",
       "      <td>1.925463</td>\n",
       "      <td>49.592594</td>\n",
       "      <td>44.222220</td>\n",
       "      <td>61.555557</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>-16.111110</td>\n",
       "      <td>35.88889</td>\n",
       "      <td>-19.777779</td>\n",
       "      <td>61.555557</td>\n",
       "      <td>0.302925</td>\n",
       "      <td>-2.022274</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region-centroid-col  region-centroid-row  ...  hue-mean  target\n",
       "0                218.0                178.0  ... -2.040554       6\n",
       "1                113.0                130.0  ... -2.123254       3\n",
       "2                202.0                 41.0  ... -2.299918       2\n",
       "3                 32.0                173.0  ... -1.998858       6\n",
       "4                 61.0                197.0  ... -2.022274       6\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7w3KipGP8PS"
   },
   "source": [
    "# 2. Split the data into training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8QMPA7umk_T"
   },
   "outputs": [],
   "source": [
    "dataset[\"target\"]=dataset[\"target\"]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnRN8LIyQKlW"
   },
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['target']).values\n",
    "Y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "0K8IQCMMb3nl",
    "outputId": "dccc2025-2e67-4099-9a25-46388a100bce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.1800000e+02,  1.7800000e+02,  9.0000000e+00, ...,\n",
       "         7.5222220e+01,  3.1899637e-01, -2.0405545e+00],\n",
       "       [ 1.1300000e+02,  1.3000000e+02,  9.0000000e+00, ...,\n",
       "         2.5555556e+00,  1.0000000e+00, -2.1232540e+00],\n",
       "       [ 2.0200000e+02,  4.1000000e+01,  9.0000000e+00, ...,\n",
       "         1.3977779e+02,  1.9934683e-01, -2.2999177e+00],\n",
       "       ...,\n",
       "       [ 8.0000000e+01,  7.2000000e+01,  9.0000000e+00, ...,\n",
       "         7.4444440e+01,  3.1460637e-01, -2.0902212e+00],\n",
       "       [ 9.8000000e+01,  1.3300000e+02,  9.0000000e+00, ...,\n",
       "         2.7777777e+00,  1.0000000e+00, -2.1232540e+00],\n",
       "       [ 1.9000000e+01,  1.4700000e+02,  9.0000000e+00, ...,\n",
       "         7.0000000e+00,  7.1322750e-01, -1.4756428e+00]])"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPiFIh4Nb41Z"
   },
   "source": [
    "### Scaling X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JcYFQYRb7y-"
   },
   "outputs": [],
   "source": [
    "scaled_data = StandardScaler().fit_transform(X)   # We are scaling values of X\n",
    "X = scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "6R0esL7cb94c",
    "outputId": "9370ffd7-04d7-4c43-81f6-2692428cdbca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.2761887 ,  0.94973634,  0.        , ...,  0.70107239,\n",
       "        -0.47269171, -0.43861303],\n",
       "       [-0.16333606,  0.11453842,  0.        , ..., -0.99229694,\n",
       "         2.51076421, -0.49214018],\n",
       "       [ 1.05683255, -1.43405774,  0.        , ...,  2.20542688,\n",
       "        -0.99687265, -0.60648555],\n",
       "       ...,\n",
       "       [-0.61575812, -0.89465908,  0.        , ...,  0.68294759,\n",
       "        -0.49192416, -0.47075974],\n",
       "       [-0.36898245,  0.16673829,  0.        , ..., -0.98711844,\n",
       "         2.51076421, -0.49214018],\n",
       "       [-1.45205346,  0.41033768,  0.        , ..., -0.88872695,\n",
       "         1.25442272, -0.07297461]])"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5ZULv-tT4Nh"
   },
   "source": [
    "### Checking the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Sr4S9I89QK3A",
    "outputId": "dbe883c1-99f7-4920-883e-9110c525c505"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2310, 19)"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "j-eIBgi_QLCO",
    "outputId": "2794998b-d4c9-4802-bd6f-3873c0a065a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2310,)"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXYukW4mUSyp"
   },
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWn7u5DUQLFO"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVGW8qqAVWuR"
   },
   "source": [
    "### Checking the splitting shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "cn-tCsKvVUYW",
    "outputId": "dbf9cb93-76c4-42f1-ad98-5c69b2a0720a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1131, 19)\n",
      "(1131,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "8t4zfENrVvYv",
    "outputId": "9f11eab8-9eb4-43ca-930b-caf1ff0348e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693, 19)\n",
      "(693,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print (Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "C0dSsy6hVvVL",
    "outputId": "c3c3f5a2-8fe8-4330-c8fe-2ffc5d7e0faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486, 19)\n",
      "(486,)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape)\n",
    "print (Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t1gZbgdY6L4"
   },
   "source": [
    "### Find the unique numbers from the train labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "LJYFQXaJVvSU",
    "outputId": "7b82cfd0-a312-417b-9d1f-a659694e19b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  7\n",
      "Output classes :  [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(Y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma3FYA78fAAh"
   },
   "source": [
    "### Convert from categorical labels to one-hot encoded vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDVxH3D4VvKO"
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train,7)\n",
    "\n",
    "Y_val = np_utils.to_categorical(Y_val, 7)\n",
    "Y_test = np_utils.to_categorical(Y_test, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO3rNuyzcnaA"
   },
   "source": [
    "### Check of the conersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "JxuADhJMRAB4",
    "outputId": "28d1e6d9-73c1-4bc1-fc8a-07c01fe2513e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "BJmPfQJDZnWs",
    "outputId": "7d531c89-5782-4061-8f7c-3421403a9b8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "g4ifo7OUZnai",
    "outputId": "ec46c83d-21fc-41ce-fc13-42d2df7e7346"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qVa13dLtRvl"
   },
   "source": [
    "# 4. Creation of NN model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWGUBI2RfoMN"
   },
   "source": [
    "### Network1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pospSRpIZmqw"
   },
   "outputs": [],
   "source": [
    "def network1():\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(21, input_dim=19, activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRBfFeGygGb8"
   },
   "source": [
    "**network1**: simple network with one layer, 19 inputs(19 features) and 21 filters between the inputs and the 7 outputs. the activation fuctions used is \"**relu**\" for the filters and \"softmax\" for the output.\n",
    "\n",
    "  Validation performance on the training was:contrary to the no scaling case accuracy around 95%, the confusion *matrix has less prediction errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWzaGw18fsEU"
   },
   "source": [
    "### Network2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qaX9Gsvdfv-d"
   },
   "outputs": [],
   "source": [
    "def network2():\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(21, input_dim=19, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-3kcwrrgCcO"
   },
   "source": [
    "**network2**: network with 2 layers, 19 inputs(19 features), 21 filters between layer 1 and layer 2 and 10 filters between layer 2 and the 7 outputs. the activation fuctions used are \"relu\" for the both layers and \"softmax\" for the output.\n",
    "\n",
    "  Validation performance on training :the accuracy is around 95% just 1% more then the **network1** and above and the confusion *matrix* which has shown few prediction errors too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUhFIexkf0_A"
   },
   "source": [
    "### Network3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1rk7zaDf3a2"
   },
   "outputs": [],
   "source": [
    "def network3():\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(21, input_dim=19, activation='relu'))\n",
    "    model.add(Dense(10, activation='linear'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WO4AawHTfiK3"
   },
   "source": [
    "**network3**: network with 3 layers, 19 inputs(19 features), 21 filters between layer 1 and layer 2, 10 filters between layer 2 and layer 2, 15 filters between layer2 and layer3 and the 7 outputs. the activation fuctions used are respectively \"relu\",\"lnear\",\"relu\" for layers and \"softmax\" for the output.\n",
    "\n",
    "This network has shown better  Validation performance on the training :accuracy almost 97% and the confusion *matrix* is better from the two previous networks. But the difference are not consirables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZdEiQffiY0q"
   },
   "source": [
    "## Choice of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqbIGy2ZicX0"
   },
   "source": [
    "Based on the validation performance on the training and validation data! We decide to use the **network3** on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKfNBl7jgOEY"
   },
   "source": [
    "## Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJ7aKwQpZmoB"
   },
   "outputs": [],
   "source": [
    "model = network3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "I9-b7pgtZml3",
    "outputId": "c2539ecc-b9ad-4686-be7f-b0f43b11534b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 21)                420       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                220       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 7)                 112       \n",
      "=================================================================\n",
      "Total params: 917\n",
      "Trainable params: 917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhSW45ZcvIZy"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lKKAY2_8Zmjn",
    "outputId": "6005be85-0a6a-4bef-9f03-28c6381142f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1131 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1131/1131 [==============================] - 1s 830us/step - loss: 1.9046 - acc: 0.1786 - val_loss: 1.7128 - val_acc: 0.2716\n",
      "Epoch 2/100\n",
      "1131/1131 [==============================] - 0s 62us/step - loss: 1.5483 - acc: 0.3846 - val_loss: 1.4351 - val_acc: 0.4979\n",
      "Epoch 3/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 1.2648 - acc: 0.5650 - val_loss: 1.1880 - val_acc: 0.5617\n",
      "Epoch 4/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 1.0304 - acc: 0.6561 - val_loss: 1.0062 - val_acc: 0.6667\n",
      "Epoch 5/100\n",
      "1131/1131 [==============================] - 0s 67us/step - loss: 0.8545 - acc: 0.7347 - val_loss: 0.8450 - val_acc: 0.7325\n",
      "Epoch 6/100\n",
      "1131/1131 [==============================] - 0s 73us/step - loss: 0.7054 - acc: 0.7940 - val_loss: 0.7085 - val_acc: 0.7737\n",
      "Epoch 7/100\n",
      "1131/1131 [==============================] - 0s 70us/step - loss: 0.5839 - acc: 0.8187 - val_loss: 0.5919 - val_acc: 0.8148\n",
      "Epoch 8/100\n",
      "1131/1131 [==============================] - 0s 66us/step - loss: 0.4926 - acc: 0.8550 - val_loss: 0.5052 - val_acc: 0.8642\n",
      "Epoch 9/100\n",
      "1131/1131 [==============================] - 0s 65us/step - loss: 0.4233 - acc: 0.8736 - val_loss: 0.4435 - val_acc: 0.8663\n",
      "Epoch 10/100\n",
      "1131/1131 [==============================] - 0s 68us/step - loss: 0.3699 - acc: 0.8851 - val_loss: 0.3925 - val_acc: 0.8786\n",
      "Epoch 11/100\n",
      "1131/1131 [==============================] - 0s 67us/step - loss: 0.3296 - acc: 0.8957 - val_loss: 0.3505 - val_acc: 0.8868\n",
      "Epoch 12/100\n",
      "1131/1131 [==============================] - 0s 66us/step - loss: 0.2985 - acc: 0.9054 - val_loss: 0.3196 - val_acc: 0.9074\n",
      "Epoch 13/100\n",
      "1131/1131 [==============================] - 0s 66us/step - loss: 0.2697 - acc: 0.9169 - val_loss: 0.2918 - val_acc: 0.9218\n",
      "Epoch 14/100\n",
      "1131/1131 [==============================] - 0s 57us/step - loss: 0.2492 - acc: 0.9160 - val_loss: 0.2744 - val_acc: 0.9239\n",
      "Epoch 15/100\n",
      "1131/1131 [==============================] - 0s 52us/step - loss: 0.2315 - acc: 0.9222 - val_loss: 0.2554 - val_acc: 0.9280\n",
      "Epoch 16/100\n",
      "1131/1131 [==============================] - 0s 54us/step - loss: 0.2138 - acc: 0.9293 - val_loss: 0.2404 - val_acc: 0.9259\n",
      "Epoch 17/100\n",
      "1131/1131 [==============================] - 0s 62us/step - loss: 0.2016 - acc: 0.9284 - val_loss: 0.2228 - val_acc: 0.9362\n",
      "Epoch 18/100\n",
      "1131/1131 [==============================] - 0s 56us/step - loss: 0.1884 - acc: 0.9310 - val_loss: 0.2198 - val_acc: 0.9424\n",
      "Epoch 19/100\n",
      "1131/1131 [==============================] - 0s 58us/step - loss: 0.1790 - acc: 0.9337 - val_loss: 0.2041 - val_acc: 0.9403\n",
      "Epoch 20/100\n",
      "1131/1131 [==============================] - 0s 56us/step - loss: 0.1696 - acc: 0.9319 - val_loss: 0.2044 - val_acc: 0.9342\n",
      "Epoch 21/100\n",
      "1131/1131 [==============================] - 0s 68us/step - loss: 0.1595 - acc: 0.9346 - val_loss: 0.1931 - val_acc: 0.9527\n",
      "Epoch 22/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.1503 - acc: 0.9461 - val_loss: 0.1873 - val_acc: 0.9424\n",
      "Epoch 23/100\n",
      "1131/1131 [==============================] - 0s 54us/step - loss: 0.1431 - acc: 0.9469 - val_loss: 0.1790 - val_acc: 0.9527\n",
      "Epoch 24/100\n",
      "1131/1131 [==============================] - 0s 53us/step - loss: 0.1373 - acc: 0.9514 - val_loss: 0.1729 - val_acc: 0.9486\n",
      "Epoch 25/100\n",
      "1131/1131 [==============================] - 0s 58us/step - loss: 0.1328 - acc: 0.9514 - val_loss: 0.1665 - val_acc: 0.9568\n",
      "Epoch 26/100\n",
      "1131/1131 [==============================] - 0s 58us/step - loss: 0.1283 - acc: 0.9523 - val_loss: 0.1625 - val_acc: 0.9609\n",
      "Epoch 27/100\n",
      "1131/1131 [==============================] - 0s 52us/step - loss: 0.1247 - acc: 0.9523 - val_loss: 0.1586 - val_acc: 0.9527\n",
      "Epoch 28/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.1191 - acc: 0.9514 - val_loss: 0.1598 - val_acc: 0.9506\n",
      "Epoch 29/100\n",
      "1131/1131 [==============================] - 0s 60us/step - loss: 0.1158 - acc: 0.9611 - val_loss: 0.1556 - val_acc: 0.9568\n",
      "Epoch 30/100\n",
      "1131/1131 [==============================] - 0s 75us/step - loss: 0.1096 - acc: 0.9584 - val_loss: 0.1532 - val_acc: 0.9527\n",
      "Epoch 31/100\n",
      "1131/1131 [==============================] - 0s 69us/step - loss: 0.1077 - acc: 0.9584 - val_loss: 0.1479 - val_acc: 0.9588\n",
      "Epoch 32/100\n",
      "1131/1131 [==============================] - 0s 69us/step - loss: 0.1022 - acc: 0.9655 - val_loss: 0.1471 - val_acc: 0.9609\n",
      "Epoch 33/100\n",
      "1131/1131 [==============================] - 0s 67us/step - loss: 0.1002 - acc: 0.9682 - val_loss: 0.1437 - val_acc: 0.9671\n",
      "Epoch 34/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0984 - acc: 0.9664 - val_loss: 0.1418 - val_acc: 0.9650\n",
      "Epoch 35/100\n",
      "1131/1131 [==============================] - 0s 59us/step - loss: 0.0933 - acc: 0.9673 - val_loss: 0.1453 - val_acc: 0.9630\n",
      "Epoch 36/100\n",
      "1131/1131 [==============================] - 0s 74us/step - loss: 0.0968 - acc: 0.9655 - val_loss: 0.1403 - val_acc: 0.9630\n",
      "Epoch 37/100\n",
      "1131/1131 [==============================] - 0s 69us/step - loss: 0.0912 - acc: 0.9717 - val_loss: 0.1384 - val_acc: 0.9609\n",
      "Epoch 38/100\n",
      "1131/1131 [==============================] - 0s 61us/step - loss: 0.0902 - acc: 0.9691 - val_loss: 0.1403 - val_acc: 0.9630\n",
      "Epoch 39/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0887 - acc: 0.9744 - val_loss: 0.1429 - val_acc: 0.9588\n",
      "Epoch 40/100\n",
      "1131/1131 [==============================] - 0s 54us/step - loss: 0.0903 - acc: 0.9664 - val_loss: 0.1428 - val_acc: 0.9588\n",
      "Epoch 41/100\n",
      "1131/1131 [==============================] - 0s 70us/step - loss: 0.0828 - acc: 0.9744 - val_loss: 0.1396 - val_acc: 0.9650\n",
      "Epoch 42/100\n",
      "1131/1131 [==============================] - 0s 69us/step - loss: 0.0823 - acc: 0.9708 - val_loss: 0.1350 - val_acc: 0.9650\n",
      "Epoch 43/100\n",
      "1131/1131 [==============================] - 0s 54us/step - loss: 0.0845 - acc: 0.9708 - val_loss: 0.1386 - val_acc: 0.9671\n",
      "Epoch 44/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0799 - acc: 0.9761 - val_loss: 0.1389 - val_acc: 0.9691\n",
      "Epoch 45/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0784 - acc: 0.9708 - val_loss: 0.1388 - val_acc: 0.9630\n",
      "Epoch 46/100\n",
      "1131/1131 [==============================] - 0s 56us/step - loss: 0.0779 - acc: 0.9752 - val_loss: 0.1434 - val_acc: 0.9691\n",
      "Epoch 47/100\n",
      "1131/1131 [==============================] - 0s 61us/step - loss: 0.0791 - acc: 0.9744 - val_loss: 0.1357 - val_acc: 0.9671\n",
      "Epoch 48/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0730 - acc: 0.9761 - val_loss: 0.1413 - val_acc: 0.9630\n",
      "Epoch 49/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0741 - acc: 0.9761 - val_loss: 0.1465 - val_acc: 0.9609\n",
      "Epoch 50/100\n",
      "1131/1131 [==============================] - 0s 57us/step - loss: 0.0740 - acc: 0.9770 - val_loss: 0.1359 - val_acc: 0.9691\n",
      "Epoch 51/100\n",
      "1131/1131 [==============================] - 0s 53us/step - loss: 0.0703 - acc: 0.9797 - val_loss: 0.1386 - val_acc: 0.9712\n",
      "Epoch 52/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0728 - acc: 0.9788 - val_loss: 0.1366 - val_acc: 0.9733\n",
      "Epoch 53/100\n",
      "1131/1131 [==============================] - 0s 59us/step - loss: 0.0696 - acc: 0.9797 - val_loss: 0.1347 - val_acc: 0.9733\n",
      "Epoch 54/100\n",
      "1131/1131 [==============================] - 0s 58us/step - loss: 0.0684 - acc: 0.9814 - val_loss: 0.1431 - val_acc: 0.9588\n",
      "Epoch 55/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0699 - acc: 0.9797 - val_loss: 0.1359 - val_acc: 0.9733\n",
      "Epoch 56/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0655 - acc: 0.9841 - val_loss: 0.1358 - val_acc: 0.9733\n",
      "Epoch 57/100\n",
      "1131/1131 [==============================] - 0s 68us/step - loss: 0.0661 - acc: 0.9805 - val_loss: 0.1421 - val_acc: 0.9650\n",
      "Epoch 58/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0644 - acc: 0.9805 - val_loss: 0.1349 - val_acc: 0.9712\n",
      "Epoch 59/100\n",
      "1131/1131 [==============================] - 0s 57us/step - loss: 0.0652 - acc: 0.9823 - val_loss: 0.1414 - val_acc: 0.9712\n",
      "Epoch 60/100\n",
      "1131/1131 [==============================] - 0s 59us/step - loss: 0.0653 - acc: 0.9814 - val_loss: 0.1378 - val_acc: 0.9691\n",
      "Epoch 61/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0627 - acc: 0.9832 - val_loss: 0.1411 - val_acc: 0.9691\n",
      "Epoch 62/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0634 - acc: 0.9814 - val_loss: 0.1401 - val_acc: 0.9712\n",
      "Epoch 63/100\n",
      "1131/1131 [==============================] - 0s 64us/step - loss: 0.0669 - acc: 0.9797 - val_loss: 0.1462 - val_acc: 0.9712\n",
      "Epoch 64/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0670 - acc: 0.9779 - val_loss: 0.1447 - val_acc: 0.9671\n",
      "Epoch 65/100\n",
      "1131/1131 [==============================] - 0s 57us/step - loss: 0.0615 - acc: 0.9823 - val_loss: 0.1377 - val_acc: 0.9733\n",
      "Epoch 66/100\n",
      "1131/1131 [==============================] - 0s 59us/step - loss: 0.0604 - acc: 0.9805 - val_loss: 0.1438 - val_acc: 0.9691\n",
      "Epoch 67/100\n",
      "1131/1131 [==============================] - 0s 60us/step - loss: 0.0592 - acc: 0.9841 - val_loss: 0.1360 - val_acc: 0.9753\n",
      "Epoch 68/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0631 - acc: 0.9805 - val_loss: 0.1390 - val_acc: 0.9712\n",
      "Epoch 69/100\n",
      "1131/1131 [==============================] - 0s 64us/step - loss: 0.0731 - acc: 0.9779 - val_loss: 0.1463 - val_acc: 0.9671\n",
      "Epoch 70/100\n",
      "1131/1131 [==============================] - 0s 69us/step - loss: 0.0586 - acc: 0.9823 - val_loss: 0.1435 - val_acc: 0.9712\n",
      "Epoch 71/100\n",
      "1131/1131 [==============================] - 0s 67us/step - loss: 0.0587 - acc: 0.9841 - val_loss: 0.1387 - val_acc: 0.9712\n",
      "Epoch 72/100\n",
      "1131/1131 [==============================] - 0s 58us/step - loss: 0.0563 - acc: 0.9850 - val_loss: 0.1385 - val_acc: 0.9733\n",
      "Epoch 73/100\n",
      "1131/1131 [==============================] - 0s 60us/step - loss: 0.0550 - acc: 0.9850 - val_loss: 0.1365 - val_acc: 0.9753\n",
      "Epoch 74/100\n",
      "1131/1131 [==============================] - 0s 54us/step - loss: 0.0583 - acc: 0.9814 - val_loss: 0.1451 - val_acc: 0.9733\n",
      "Epoch 75/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0598 - acc: 0.9841 - val_loss: 0.1499 - val_acc: 0.9733\n",
      "Epoch 76/100\n",
      "1131/1131 [==============================] - 0s 58us/step - loss: 0.0604 - acc: 0.9805 - val_loss: 0.1443 - val_acc: 0.9691\n",
      "Epoch 77/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0560 - acc: 0.9850 - val_loss: 0.1397 - val_acc: 0.9733\n",
      "Epoch 78/100\n",
      "1131/1131 [==============================] - 0s 53us/step - loss: 0.0555 - acc: 0.9823 - val_loss: 0.1368 - val_acc: 0.9774\n",
      "Epoch 79/100\n",
      "1131/1131 [==============================] - 0s 61us/step - loss: 0.0564 - acc: 0.9823 - val_loss: 0.1390 - val_acc: 0.9774\n",
      "Epoch 80/100\n",
      "1131/1131 [==============================] - 0s 58us/step - loss: 0.0552 - acc: 0.9850 - val_loss: 0.1478 - val_acc: 0.9691\n",
      "Epoch 81/100\n",
      "1131/1131 [==============================] - 0s 56us/step - loss: 0.0530 - acc: 0.9850 - val_loss: 0.1487 - val_acc: 0.9691\n",
      "Epoch 82/100\n",
      "1131/1131 [==============================] - 0s 58us/step - loss: 0.0553 - acc: 0.9814 - val_loss: 0.1556 - val_acc: 0.9650\n",
      "Epoch 83/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0624 - acc: 0.9797 - val_loss: 0.1376 - val_acc: 0.9774\n",
      "Epoch 84/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0527 - acc: 0.9850 - val_loss: 0.1399 - val_acc: 0.9774\n",
      "Epoch 85/100\n",
      "1131/1131 [==============================] - 0s 59us/step - loss: 0.0525 - acc: 0.9841 - val_loss: 0.1389 - val_acc: 0.9774\n",
      "Epoch 86/100\n",
      "1131/1131 [==============================] - 0s 57us/step - loss: 0.0502 - acc: 0.9859 - val_loss: 0.1452 - val_acc: 0.9712\n",
      "Epoch 87/100\n",
      "1131/1131 [==============================] - 0s 61us/step - loss: 0.0500 - acc: 0.9850 - val_loss: 0.1444 - val_acc: 0.9712\n",
      "Epoch 88/100\n",
      "1131/1131 [==============================] - 0s 55us/step - loss: 0.0504 - acc: 0.9841 - val_loss: 0.1417 - val_acc: 0.9753\n",
      "Epoch 89/100\n",
      "1131/1131 [==============================] - 0s 52us/step - loss: 0.0517 - acc: 0.9867 - val_loss: 0.1475 - val_acc: 0.9671\n",
      "Epoch 90/100\n",
      "1131/1131 [==============================] - 0s 54us/step - loss: 0.0508 - acc: 0.9850 - val_loss: 0.1436 - val_acc: 0.9774\n",
      "Epoch 91/100\n",
      "1131/1131 [==============================] - 0s 53us/step - loss: 0.0526 - acc: 0.9850 - val_loss: 0.1376 - val_acc: 0.9774\n",
      "Epoch 92/100\n",
      "1131/1131 [==============================] - 0s 60us/step - loss: 0.0499 - acc: 0.9867 - val_loss: 0.1429 - val_acc: 0.9753\n",
      "Epoch 93/100\n",
      "1131/1131 [==============================] - 0s 53us/step - loss: 0.0508 - acc: 0.9859 - val_loss: 0.1482 - val_acc: 0.9712\n",
      "Epoch 94/100\n",
      "1131/1131 [==============================] - 0s 53us/step - loss: 0.0503 - acc: 0.9859 - val_loss: 0.1360 - val_acc: 0.9774\n",
      "Epoch 95/100\n",
      "1131/1131 [==============================] - 0s 61us/step - loss: 0.0497 - acc: 0.9850 - val_loss: 0.1401 - val_acc: 0.9774\n",
      "Epoch 96/100\n",
      "1131/1131 [==============================] - 0s 58us/step - loss: 0.0472 - acc: 0.9859 - val_loss: 0.1565 - val_acc: 0.9671\n",
      "Epoch 97/100\n",
      "1131/1131 [==============================] - 0s 71us/step - loss: 0.0470 - acc: 0.9885 - val_loss: 0.1383 - val_acc: 0.9753\n",
      "Epoch 98/100\n",
      "1131/1131 [==============================] - 0s 59us/step - loss: 0.0474 - acc: 0.9859 - val_loss: 0.1382 - val_acc: 0.9753\n",
      "Epoch 99/100\n",
      "1131/1131 [==============================] - 0s 54us/step - loss: 0.0526 - acc: 0.9797 - val_loss: 0.1409 - val_acc: 0.9753\n",
      "Epoch 100/100\n",
      "1131/1131 [==============================] - 0s 56us/step - loss: 0.0468 - acc: 0.9859 - val_loss: 0.1442 - val_acc: 0.9733\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val) ,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sM9XFoqtvMZf"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "yvLhUQtsvMjb",
    "outputId": "59ef0935-8502-48c3-c8ca-a8279482a3ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1565198e-26, 9.9999988e-01, 6.5064887e-09, ..., 1.8815097e-11,\n",
       "        4.1323736e-11, 7.2935254e-17],\n",
       "       [1.4258785e-14, 2.0101574e-08, 2.4653892e-14, ..., 1.5795626e-10,\n",
       "        9.9998248e-01, 6.8065581e-11],\n",
       "       [1.6246929e-27, 9.9999988e-01, 2.7776842e-08, ..., 2.7035612e-11,\n",
       "        3.9489179e-19, 2.2177704e-20],\n",
       "       ...,\n",
       "       [1.5992461e-14, 1.1208834e-10, 1.1435838e-14, ..., 4.7471509e-11,\n",
       "        9.9999976e-01, 1.3368705e-10],\n",
       "       [1.9143547e-04, 8.8589331e-09, 1.0432067e-03, ..., 9.9664491e-01,\n",
       "        2.3128875e-16, 3.5322797e-12],\n",
       "       [8.9153407e-10, 1.2853208e-05, 3.6283240e-11, ..., 2.4229544e-06,\n",
       "        7.6117940e-12, 1.5119327e-12]], dtype=float32)"
      ]
     },
     "execution_count": 246,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrHg8gDwvMnu"
   },
   "outputs": [],
   "source": [
    "prediction_classes = model.predict_classes(X_test)\n",
    "prediction_classes_val = model.predict_classes(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "GHkUGMWovMgM",
    "outputId": "222bdd8d-c4f6-4202-ca38-4fb6a96bb207"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 1, 2, 5, 2, 0, 2, 2, 0, 0, 4, 2, 1, 0, 0, 5, 6, 1, 3, 5, 6,\n",
       "       4, 5, 0, 2, 3, 2, 6, 0, 2, 3, 0, 3, 5, 5, 6, 0, 5, 4, 4, 0, 5, 3,\n",
       "       2, 5, 2, 6, 2, 0, 2, 2, 4, 0, 6, 1, 3, 1, 5, 5, 2, 2, 2, 0, 0, 3,\n",
       "       6, 6, 1, 6, 1, 6, 5, 5, 1, 4, 6, 2, 0, 1, 3, 4, 5, 6, 3, 5, 0, 0,\n",
       "       0, 3, 6, 2, 0, 0, 5, 4, 0, 6, 0, 4, 3, 2, 6, 4, 1, 0, 5, 1, 4, 6,\n",
       "       1, 0, 2, 0, 4, 5, 2, 4, 2, 1, 3, 4, 6, 2, 0, 1, 3, 0, 0, 6, 5, 0,\n",
       "       6, 2, 1, 3, 4, 6, 3, 3, 0, 1, 4, 5, 6, 6, 3, 1, 5, 0, 3, 2, 0, 1,\n",
       "       1, 0, 3, 2, 3, 4, 0, 1, 2, 4, 6, 5, 5, 4, 4, 3, 4, 2, 0, 3, 4, 0,\n",
       "       6, 3, 4, 6, 2, 3, 1, 4, 3, 5, 2, 4, 5, 4, 2, 2, 6, 2, 2, 3, 4, 4,\n",
       "       3, 4, 5, 4, 1, 4, 4, 0, 5, 5, 3, 0, 1, 1, 6, 4, 0, 3, 3, 2, 1, 3,\n",
       "       4, 6, 2, 5, 0, 3, 0, 0, 1, 6, 0, 3, 3, 5, 1, 5, 6, 5, 1, 3, 6, 0,\n",
       "       2, 3, 5, 5, 0, 0, 3, 4, 6, 1, 3, 1, 3, 4, 3, 3, 1, 1, 0, 4, 6, 5,\n",
       "       4, 1, 0, 0, 3, 0, 2, 4, 6, 0, 3, 3, 5, 4, 0, 1, 5, 2, 5, 3, 4, 2,\n",
       "       3, 2, 4, 1, 3, 2, 4, 0, 4, 3, 1, 0, 3, 0, 2, 2, 5, 5, 5, 1, 3, 1,\n",
       "       3, 1, 3, 4, 0, 4, 3, 3, 3, 3, 5, 6, 2, 1, 4, 6, 4, 0, 5, 4, 0, 3,\n",
       "       5, 2, 6, 5, 6, 0, 3, 3, 2, 1, 2, 6, 1, 6, 6, 4, 6, 1, 3, 6, 2, 5,\n",
       "       2, 4, 6, 4, 5, 6, 1, 0, 2, 1, 2, 2, 4, 0, 3, 0, 6, 3, 1, 1, 1, 5,\n",
       "       5, 2, 0, 2, 6, 3, 6, 3, 2, 4, 1, 0, 4, 2, 6, 4, 0, 0, 4, 4, 0, 0,\n",
       "       1, 2, 0, 4, 2, 5, 5, 5, 1, 5, 6, 0, 2, 4, 4, 2, 6, 0, 4, 4, 0, 1,\n",
       "       4, 2, 0, 1, 5, 6, 2, 5, 6, 2, 2, 4, 6, 6, 3, 2, 3, 1, 2, 0, 6, 4,\n",
       "       4, 6, 1, 4, 2, 0, 2, 1, 3, 1, 6, 4, 4, 1, 5, 5, 3, 3, 3, 0, 6, 5,\n",
       "       5, 5, 5, 0, 2, 2, 3, 0, 0, 3, 2, 0, 4, 4, 5, 0, 1, 3, 4, 3, 0, 5,\n",
       "       3, 1, 6, 5, 0, 2, 4, 5, 1, 0, 5, 2, 0, 1, 4, 0, 3, 6, 6, 3, 0, 3,\n",
       "       4, 6, 5, 3, 6, 6, 6, 4, 4, 6, 2, 6, 1, 6, 5, 0, 2, 3, 0, 4, 0, 1,\n",
       "       0, 6, 3, 0, 2, 5, 0, 1, 3, 6, 4, 5, 5, 5, 5, 0, 4, 5, 1, 1, 1, 4,\n",
       "       1, 0, 2, 3, 4, 2, 3, 1, 0, 0, 2, 4, 1, 4, 4, 5, 2, 5, 3, 0, 5, 0,\n",
       "       2, 2, 1, 1, 1, 4, 3, 0, 2, 3, 5, 4, 2, 2, 3, 4, 0, 4, 5, 5, 1, 1,\n",
       "       1, 6, 6, 5, 2, 1, 4, 6, 4, 0, 3, 3, 1, 6, 6, 0, 2, 1, 6, 2, 4, 1,\n",
       "       0, 3, 2, 1, 6, 3, 4, 0, 0, 1, 3, 0, 0, 2, 3, 0, 6, 0, 2, 1, 3, 6,\n",
       "       3, 2, 2, 4, 2, 3, 4, 3, 6, 4, 3, 1, 3, 1, 0, 3, 3, 5, 1, 0, 6, 1,\n",
       "       5, 4, 4, 2, 1, 5, 4, 0, 0, 4, 1, 4, 1, 6, 3, 1, 0, 0, 2, 2, 5, 4,\n",
       "       3, 1, 6, 5, 6, 3, 2, 3, 5, 4, 3])"
      ]
     },
     "execution_count": 248,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "y7YXBhF0vMeK",
    "outputId": "3f8987b3-f81a-4a98-9775-d06ebdbeca1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 249,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8ttCIdUjNvw"
   },
   "source": [
    "# 5) Plot the confusion matrix and describe two of the errors which were made by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6E9EF3k9jsp9"
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "VOTkHysOvMXW",
    "outputId": "08ba2244-6641-41fd-bf6c-9ac37e4676f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[110,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,  94,   0,   0,   0,   0,   0],\n",
       "       [  2,   0,  91,   2,   6,   0,   0],\n",
       "       [  0,   0,   1, 104,   4,   1,   0],\n",
       "       [  4,   0,   7,   1,  94,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  87,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85]])"
      ]
     },
     "execution_count": 250,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.argmax(Y_test,1), prediction_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tt3C_XTljwAy"
   },
   "source": [
    "## Mean square errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hjo3tu-FkbzL"
   },
   "outputs": [],
   "source": [
    "val_prediction = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JasUUsKWk3gn"
   },
   "source": [
    "### For the validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gDuwrNPjj3c0",
    "outputId": "29479fcf-8cdc-41bb-c10c-7b7a8b7758f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0063390606"
      ]
     },
     "execution_count": 252,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_val, val_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgCf7gANk9Zo"
   },
   "source": [
    "### For the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XklyxN_XksAD",
    "outputId": "36fcabfc-bac5-47ec-d792-ccf380a55ebe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008710656"
      ]
     },
     "execution_count": 253,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrsHDR1ly6ll"
   },
   "source": [
    "# 6. Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APpWEDj2lVbp"
   },
   "source": [
    "### For the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "SbTwLDynVu7l",
    "outputId": "4fca33c9-9fca-4aee-9199-96f501336be9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9595959595959596"
      ]
     },
     "execution_count": 258,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(Y_test,1), prediction_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r96IVOMhWR8o"
   },
   "source": [
    "### For the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "im1EwfcaWWLx",
    "outputId": "07b4c290-555a-4dd8-c662-ef7e24826d1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732510288065843"
      ]
     },
     "execution_count": 255,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(Y_val,1), prediction_classes_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFArDoYszFz4"
   },
   "source": [
    "# 7. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_z3YDsMy_cK"
   },
   "outputs": [],
   "source": [
    "def plot_hist(h, xsize=6, ysize=10):\n",
    "\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    plt.rcParams[\"figure.figsize\"] = [xsize, ysize]\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, sharex=True)\n",
    "    \n",
    "    # summarize history for Accuracy\n",
    "    plt.subplot(211)\n",
    "    plt.plot(h['acc'])\n",
    "    plt.plot(h['val_acc'])\n",
    "    plt.title('Training Performance')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    \n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "WfLl08Y3y_qA",
    "outputId": "13a58ac1-4616-429c-82a8-144a90af99b5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAFlCAYAAAD7xdEoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxCMiIhoqSTwiIqKh/gRWlv5HsnFqggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history.history, xsize=8, ysize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RS3eiMtwY0vN"
   },
   "source": [
    "# 8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzlEphtGY7Ux"
   },
   "source": [
    "We still have an overfitting! Because the predicting data is perfectly fitted in the training . Another reason could be the meansquare errors too small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Qrrd3usf_7V"
   },
   "source": [
    "And we notic that after **Scalling** the performance of the Same Models has increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyabfRoxxekk"
   },
   "source": [
    "# 9 Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSAkaW5wxrs0"
   },
   "source": [
    "### Save the model to the local disk\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwPWfEBBy_tB"
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6S7g_j_AyQly"
   },
   "source": [
    "## Save the model's weights to the local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lc4FR4IMy_y_"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xs33LPn9yUWR"
   },
   "source": [
    "### Load the model back into memory\n",
    "\n",
    "We first read in the JSON file then make use of *model_from_json* which we obtained as an import at the top of this script: *from keras.models import model_from_json*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZM2-YkP4y_3F"
   },
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_as_json = json_file.read()\n",
    "json_file.close()\n",
    "restored_model = model_from_json(loaded_model_as_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILDYhfflyv7v"
   },
   "source": [
    "## Load the weights back into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_awJcWWyy_wi"
   },
   "outputs": [],
   "source": [
    "restored_model.load_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykzoh2b3y3rj"
   },
   "source": [
    "## Re-compile the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xcHT-yGy9ix"
   },
   "outputs": [],
   "source": [
    "restored_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT0C1UdQy8A3"
   },
   "source": [
    "## Resume training, predict or perform other tasks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "VShA-ph2zH2y",
    "outputId": "86329122-7051-4e04-e06d-a5f6fcd5c2b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1131 samples, validate on 486 samples\n",
      "Epoch 1/2\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.0148 - acc: 0.9942 - val_loss: 0.0366 - val_acc: 0.9915\n",
      "Epoch 2/2\n",
      "1131/1131 [==============================] - 0s 239us/step - loss: 0.0145 - acc: 0.9947 - val_loss: 0.0369 - val_acc: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f189797acc0>"
      ]
     },
     "execution_count": 285,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=2, batch_size=8, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K46uB6in1TGp"
   },
   "outputs": [],
   "source": [
    "prediction_classes_val_restored = restored_model.predict_classes(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JdxdHA96X_w"
   },
   "source": [
    "## Check the accuracy of the restored model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "eTawOgRR1oFL",
    "outputId": "3682609c-f534-402e-a514-cdc5ffb6abf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9711934156378601"
      ]
     },
     "execution_count": 287,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(Y_val,1), prediction_classes_val_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlitjQQu2Z2V"
   },
   "source": [
    "## Notice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTOaosFp2B9Q"
   },
   "source": [
    "We notice that the accuracy of the restored model is approximatively the same as the accuracy of the model before saving.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZj5fZKqfW2E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "jérémie_bakambana_assign_1_scaling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
